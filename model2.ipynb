{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-support>=0.4.2 (from tflite-model-maker) (from versions: 0.1.0a0.dev3, 0.1.0a0.dev4, 0.1.0a0.dev5, 0.1.0a0, 0.1.0a1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-support>=0.4.2 (from tflite-model-maker)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from versions: 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q --use-deprecated=legacy-resolver tflite-model-maker\n",
    "!pip install -q pycocotools\n",
    "!pip install -q opencv-python-headless==4.1.2.30\n",
    "!pip uninstall -y tensorflow && pip install -q tensorflow==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'pexpect'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "!pip install pexpect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/.local/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/kevin/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "#run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = 'annotations_train.csv'\n",
    "VALIDATION = 'annotations_validation.csv'\n",
    "TEST = 'annotations_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get('efficientdet_lite0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _validation_data, _test_data = object_detector.DataLoader.from_csv(TRAINING)\n",
    "_train_data, validation_data, _test_data = object_detector.DataLoader.from_csv(VALIDATION)\n",
    "_train_data, _validation_data, test_data = object_detector.DataLoader.from_csv(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 2503\n",
      "Validation data size: 260\n",
      "Test data size: 241\n"
     ]
    }
   ],
   "source": [
    "print('Training data size:', train_data.size)\n",
    "print('Validation data size:', validation_data.size)\n",
    "print('Test data size:', test_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "312/312 [==============================] - 106s 254ms/step - det_loss: 0.7030 - cls_loss: 0.5017 - box_loss: 0.0040 - reg_l2_loss: 0.0638 - loss: 0.7668 - learning_rate: 0.0090 - gradient_norm: 1.8065 - val_det_loss: 1.0850 - val_cls_loss: 0.9977 - val_box_loss: 0.0017 - val_reg_l2_loss: 0.0638 - val_loss: 1.1488\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 78s 249ms/step - det_loss: 0.2690 - cls_loss: 0.1907 - box_loss: 0.0016 - reg_l2_loss: 0.0638 - loss: 0.3328 - learning_rate: 0.0100 - gradient_norm: 1.6276 - val_det_loss: 1.2156 - val_cls_loss: 1.1639 - val_box_loss: 0.0010 - val_reg_l2_loss: 0.0638 - val_loss: 1.2794\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.2252 - cls_loss: 0.1572 - box_loss: 0.0014 - reg_l2_loss: 0.0638 - loss: 0.2890 - learning_rate: 0.0099 - gradient_norm: 1.5380 - val_det_loss: 1.3940 - val_cls_loss: 1.3531 - val_box_loss: 8.1707e-04 - val_reg_l2_loss: 0.0638 - val_loss: 1.4578\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 78s 250ms/step - det_loss: 0.2005 - cls_loss: 0.1388 - box_loss: 0.0012 - reg_l2_loss: 0.0638 - loss: 0.2643 - learning_rate: 0.0099 - gradient_norm: 1.4178 - val_det_loss: 1.6081 - val_cls_loss: 1.5620 - val_box_loss: 9.2180e-04 - val_reg_l2_loss: 0.0638 - val_loss: 1.6719\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 87s 280ms/step - det_loss: 0.1778 - cls_loss: 0.1246 - box_loss: 0.0011 - reg_l2_loss: 0.0638 - loss: 0.2416 - learning_rate: 0.0098 - gradient_norm: 1.2901 - val_det_loss: 1.5884 - val_cls_loss: 1.5586 - val_box_loss: 5.9589e-04 - val_reg_l2_loss: 0.0638 - val_loss: 1.6521\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 78s 250ms/step - det_loss: 0.1811 - cls_loss: 0.1266 - box_loss: 0.0011 - reg_l2_loss: 0.0638 - loss: 0.2448 - learning_rate: 0.0097 - gradient_norm: 1.4143 - val_det_loss: 1.6663 - val_cls_loss: 1.6343 - val_box_loss: 6.4010e-04 - val_reg_l2_loss: 0.0637 - val_loss: 1.7300\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 78s 250ms/step - det_loss: 0.1715 - cls_loss: 0.1208 - box_loss: 0.0010 - reg_l2_loss: 0.0637 - loss: 0.2353 - learning_rate: 0.0096 - gradient_norm: 1.3329 - val_det_loss: 1.6496 - val_cls_loss: 1.6200 - val_box_loss: 5.9197e-04 - val_reg_l2_loss: 0.0637 - val_loss: 1.7133\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - 78s 251ms/step - det_loss: 0.1681 - cls_loss: 0.1167 - box_loss: 0.0010 - reg_l2_loss: 0.0637 - loss: 0.2317 - learning_rate: 0.0094 - gradient_norm: 1.3030 - val_det_loss: 1.7479 - val_cls_loss: 1.7136 - val_box_loss: 6.8682e-04 - val_reg_l2_loss: 0.0636 - val_loss: 1.8116\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1624 - cls_loss: 0.1135 - box_loss: 9.7798e-04 - reg_l2_loss: 0.0636 - loss: 0.2260 - learning_rate: 0.0093 - gradient_norm: 1.2356 - val_det_loss: 1.8674 - val_cls_loss: 1.8353 - val_box_loss: 6.4048e-04 - val_reg_l2_loss: 0.0636 - val_loss: 1.9309\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - 83s 267ms/step - det_loss: 0.1551 - cls_loss: 0.1091 - box_loss: 9.1999e-04 - reg_l2_loss: 0.0635 - loss: 0.2187 - learning_rate: 0.0091 - gradient_norm: 1.1979 - val_det_loss: 1.7544 - val_cls_loss: 1.7264 - val_box_loss: 5.6028e-04 - val_reg_l2_loss: 0.0635 - val_loss: 1.8179\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - 78s 250ms/step - det_loss: 0.1551 - cls_loss: 0.1070 - box_loss: 9.6169e-04 - reg_l2_loss: 0.0635 - loss: 0.2185 - learning_rate: 0.0089 - gradient_norm: 1.2251 - val_det_loss: 1.8005 - val_cls_loss: 1.7693 - val_box_loss: 6.2239e-04 - val_reg_l2_loss: 0.0634 - val_loss: 1.8639\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1549 - cls_loss: 0.1086 - box_loss: 9.2467e-04 - reg_l2_loss: 0.0634 - loss: 0.2183 - learning_rate: 0.0087 - gradient_norm: 1.2631 - val_det_loss: 1.8230 - val_cls_loss: 1.7899 - val_box_loss: 6.6204e-04 - val_reg_l2_loss: 0.0634 - val_loss: 1.8864\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1490 - cls_loss: 0.1038 - box_loss: 9.0390e-04 - reg_l2_loss: 0.0634 - loss: 0.2124 - learning_rate: 0.0085 - gradient_norm: 1.1905 - val_det_loss: 1.8518 - val_cls_loss: 1.8217 - val_box_loss: 6.0286e-04 - val_reg_l2_loss: 0.0633 - val_loss: 1.9151\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - 78s 251ms/step - det_loss: 0.1464 - cls_loss: 0.1021 - box_loss: 8.8604e-04 - reg_l2_loss: 0.0633 - loss: 0.2097 - learning_rate: 0.0082 - gradient_norm: 1.1618 - val_det_loss: 1.9776 - val_cls_loss: 1.9524 - val_box_loss: 5.0399e-04 - val_reg_l2_loss: 0.0633 - val_loss: 2.0408\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - 84s 268ms/step - det_loss: 0.1462 - cls_loss: 0.1021 - box_loss: 8.8213e-04 - reg_l2_loss: 0.0632 - loss: 0.2094 - learning_rate: 0.0080 - gradient_norm: 1.1349 - val_det_loss: 1.8394 - val_cls_loss: 1.8126 - val_box_loss: 5.3512e-04 - val_reg_l2_loss: 0.0632 - val_loss: 1.9025\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - 78s 252ms/step - det_loss: 0.1414 - cls_loss: 0.0996 - box_loss: 8.3469e-04 - reg_l2_loss: 0.0631 - loss: 0.2045 - learning_rate: 0.0077 - gradient_norm: 1.0994 - val_det_loss: 2.0071 - val_cls_loss: 1.9836 - val_box_loss: 4.7030e-04 - val_reg_l2_loss: 0.0631 - val_loss: 2.0702\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - 78s 251ms/step - det_loss: 0.1405 - cls_loss: 0.0993 - box_loss: 8.2456e-04 - reg_l2_loss: 0.0631 - loss: 0.2036 - learning_rate: 0.0075 - gradient_norm: 1.1421 - val_det_loss: 1.9310 - val_cls_loss: 1.9076 - val_box_loss: 4.6691e-04 - val_reg_l2_loss: 0.0630 - val_loss: 1.9940\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1391 - cls_loss: 0.0977 - box_loss: 8.2784e-04 - reg_l2_loss: 0.0630 - loss: 0.2021 - learning_rate: 0.0072 - gradient_norm: 1.0915 - val_det_loss: 1.9280 - val_cls_loss: 1.9049 - val_box_loss: 4.6064e-04 - val_reg_l2_loss: 0.0630 - val_loss: 1.9909\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1335 - cls_loss: 0.0948 - box_loss: 7.7490e-04 - reg_l2_loss: 0.0629 - loss: 0.1965 - learning_rate: 0.0069 - gradient_norm: 1.0681 - val_det_loss: 1.9610 - val_cls_loss: 1.9312 - val_box_loss: 5.9724e-04 - val_reg_l2_loss: 0.0629 - val_loss: 2.0239\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - 84s 268ms/step - det_loss: 0.1334 - cls_loss: 0.0943 - box_loss: 7.8175e-04 - reg_l2_loss: 0.0629 - loss: 0.1962 - learning_rate: 0.0066 - gradient_norm: 1.0613 - val_det_loss: 2.0666 - val_cls_loss: 2.0403 - val_box_loss: 5.2606e-04 - val_reg_l2_loss: 0.0628 - val_loss: 2.1294\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1330 - cls_loss: 0.0942 - box_loss: 7.7560e-04 - reg_l2_loss: 0.0628 - loss: 0.1957 - learning_rate: 0.0063 - gradient_norm: 1.0763 - val_det_loss: 1.9670 - val_cls_loss: 1.9393 - val_box_loss: 5.5428e-04 - val_reg_l2_loss: 0.0628 - val_loss: 2.0298\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1306 - cls_loss: 0.0932 - box_loss: 7.4711e-04 - reg_l2_loss: 0.0627 - loss: 0.1933 - learning_rate: 0.0060 - gradient_norm: 1.0587 - val_det_loss: 2.0248 - val_cls_loss: 2.0011 - val_box_loss: 4.7463e-04 - val_reg_l2_loss: 0.0627 - val_loss: 2.0875\n",
      "Epoch 23/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1271 - cls_loss: 0.0904 - box_loss: 7.3326e-04 - reg_l2_loss: 0.0627 - loss: 0.1897 - learning_rate: 0.0056 - gradient_norm: 1.0487 - val_det_loss: 2.0823 - val_cls_loss: 2.0592 - val_box_loss: 4.6346e-04 - val_reg_l2_loss: 0.0626 - val_loss: 2.1450\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1268 - cls_loss: 0.0904 - box_loss: 7.2851e-04 - reg_l2_loss: 0.0626 - loss: 0.1894 - learning_rate: 0.0053 - gradient_norm: 1.0750 - val_det_loss: 2.0361 - val_cls_loss: 2.0118 - val_box_loss: 4.8545e-04 - val_reg_l2_loss: 0.0626 - val_loss: 2.0986\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - 84s 268ms/step - det_loss: 0.1282 - cls_loss: 0.0904 - box_loss: 7.5553e-04 - reg_l2_loss: 0.0625 - loss: 0.1907 - learning_rate: 0.0050 - gradient_norm: 1.0881 - val_det_loss: 2.1347 - val_cls_loss: 2.1106 - val_box_loss: 4.8122e-04 - val_reg_l2_loss: 0.0625 - val_loss: 2.1972\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - 78s 251ms/step - det_loss: 0.1250 - cls_loss: 0.0880 - box_loss: 7.4009e-04 - reg_l2_loss: 0.0625 - loss: 0.1875 - learning_rate: 0.0047 - gradient_norm: 1.0354 - val_det_loss: 2.1088 - val_cls_loss: 2.0856 - val_box_loss: 4.6452e-04 - val_reg_l2_loss: 0.0625 - val_loss: 2.1713\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1267 - cls_loss: 0.0894 - box_loss: 7.4561e-04 - reg_l2_loss: 0.0624 - loss: 0.1892 - learning_rate: 0.0044 - gradient_norm: 1.0845 - val_det_loss: 2.1029 - val_cls_loss: 2.0786 - val_box_loss: 4.8610e-04 - val_reg_l2_loss: 0.0624 - val_loss: 2.1653\n",
      "Epoch 28/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1219 - cls_loss: 0.0873 - box_loss: 6.9191e-04 - reg_l2_loss: 0.0624 - loss: 0.1843 - learning_rate: 0.0040 - gradient_norm: 1.0599 - val_det_loss: 2.1155 - val_cls_loss: 2.0935 - val_box_loss: 4.4039e-04 - val_reg_l2_loss: 0.0624 - val_loss: 2.1778\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1232 - cls_loss: 0.0882 - box_loss: 7.0095e-04 - reg_l2_loss: 0.0623 - loss: 0.1856 - learning_rate: 0.0037 - gradient_norm: 1.0662 - val_det_loss: 2.0826 - val_cls_loss: 2.0588 - val_box_loss: 4.7610e-04 - val_reg_l2_loss: 0.0623 - val_loss: 2.1449\n",
      "Epoch 30/50\n",
      "312/312 [==============================] - 83s 267ms/step - det_loss: 0.1226 - cls_loss: 0.0874 - box_loss: 7.0450e-04 - reg_l2_loss: 0.0623 - loss: 0.1849 - learning_rate: 0.0034 - gradient_norm: 1.0519 - val_det_loss: 2.1469 - val_cls_loss: 2.1234 - val_box_loss: 4.6944e-04 - val_reg_l2_loss: 0.0623 - val_loss: 2.2092\n",
      "Epoch 31/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1182 - cls_loss: 0.0848 - box_loss: 6.6823e-04 - reg_l2_loss: 0.0623 - loss: 0.1805 - learning_rate: 0.0031 - gradient_norm: 1.0147 - val_det_loss: 2.1864 - val_cls_loss: 2.1654 - val_box_loss: 4.1949e-04 - val_reg_l2_loss: 0.0622 - val_loss: 2.2486\n",
      "Epoch 32/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1205 - cls_loss: 0.0863 - box_loss: 6.8329e-04 - reg_l2_loss: 0.0622 - loss: 0.1827 - learning_rate: 0.0028 - gradient_norm: 1.0626 - val_det_loss: 2.1228 - val_cls_loss: 2.1014 - val_box_loss: 4.2800e-04 - val_reg_l2_loss: 0.0622 - val_loss: 2.1850\n",
      "Epoch 33/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1177 - cls_loss: 0.0843 - box_loss: 6.6763e-04 - reg_l2_loss: 0.0622 - loss: 0.1799 - learning_rate: 0.0025 - gradient_norm: 1.0107 - val_det_loss: 2.0927 - val_cls_loss: 2.0700 - val_box_loss: 4.5294e-04 - val_reg_l2_loss: 0.0622 - val_loss: 2.1549\n",
      "Epoch 34/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1196 - cls_loss: 0.0861 - box_loss: 6.7049e-04 - reg_l2_loss: 0.0622 - loss: 0.1817 - learning_rate: 0.0023 - gradient_norm: 1.0367 - val_det_loss: 2.1452 - val_cls_loss: 2.1240 - val_box_loss: 4.2449e-04 - val_reg_l2_loss: 0.0621 - val_loss: 2.2073\n",
      "Epoch 35/50\n",
      "312/312 [==============================] - 84s 268ms/step - det_loss: 0.1157 - cls_loss: 0.0830 - box_loss: 6.5399e-04 - reg_l2_loss: 0.0621 - loss: 0.1778 - learning_rate: 0.0020 - gradient_norm: 1.0074 - val_det_loss: 2.1509 - val_cls_loss: 2.1300 - val_box_loss: 4.1773e-04 - val_reg_l2_loss: 0.0621 - val_loss: 2.2130\n",
      "Epoch 36/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1134 - cls_loss: 0.0817 - box_loss: 6.3473e-04 - reg_l2_loss: 0.0621 - loss: 0.1755 - learning_rate: 0.0018 - gradient_norm: 0.9890 - val_det_loss: 2.1244 - val_cls_loss: 2.1043 - val_box_loss: 4.0195e-04 - val_reg_l2_loss: 0.0621 - val_loss: 2.1865\n",
      "Epoch 37/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1146 - cls_loss: 0.0818 - box_loss: 6.5627e-04 - reg_l2_loss: 0.0621 - loss: 0.1767 - learning_rate: 0.0015 - gradient_norm: 1.0167 - val_det_loss: 2.1627 - val_cls_loss: 2.1404 - val_box_loss: 4.4583e-04 - val_reg_l2_loss: 0.0621 - val_loss: 2.2248\n",
      "Epoch 38/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1124 - cls_loss: 0.0815 - box_loss: 6.1799e-04 - reg_l2_loss: 0.0621 - loss: 0.1744 - learning_rate: 0.0013 - gradient_norm: 1.0077 - val_det_loss: 2.1754 - val_cls_loss: 2.1549 - val_box_loss: 4.1031e-04 - val_reg_l2_loss: 0.0621 - val_loss: 2.2374\n",
      "Epoch 39/50\n",
      "312/312 [==============================] - 79s 254ms/step - det_loss: 0.1126 - cls_loss: 0.0812 - box_loss: 6.2755e-04 - reg_l2_loss: 0.0620 - loss: 0.1747 - learning_rate: 0.0011 - gradient_norm: 0.9898 - val_det_loss: 2.2098 - val_cls_loss: 2.1882 - val_box_loss: 4.3134e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2718\n",
      "Epoch 40/50\n",
      "312/312 [==============================] - 83s 267ms/step - det_loss: 0.1148 - cls_loss: 0.0822 - box_loss: 6.5222e-04 - reg_l2_loss: 0.0620 - loss: 0.1768 - learning_rate: 8.9985e-04 - gradient_norm: 1.0241 - val_det_loss: 2.1790 - val_cls_loss: 2.1582 - val_box_loss: 4.1583e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2410\n",
      "Epoch 41/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1129 - cls_loss: 0.0811 - box_loss: 6.3514e-04 - reg_l2_loss: 0.0620 - loss: 0.1749 - learning_rate: 7.2502e-04 - gradient_norm: 1.0212 - val_det_loss: 2.2074 - val_cls_loss: 2.1865 - val_box_loss: 4.1633e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2694\n",
      "Epoch 42/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1125 - cls_loss: 0.0811 - box_loss: 6.2740e-04 - reg_l2_loss: 0.0620 - loss: 0.1745 - learning_rate: 5.6777e-04 - gradient_norm: 1.0224 - val_det_loss: 2.2078 - val_cls_loss: 2.1882 - val_box_loss: 3.9120e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2698\n",
      "Epoch 43/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1120 - cls_loss: 0.0809 - box_loss: 6.2377e-04 - reg_l2_loss: 0.0620 - loss: 0.1740 - learning_rate: 4.2873e-04 - gradient_norm: 1.0086 - val_det_loss: 2.2224 - val_cls_loss: 2.2024 - val_box_loss: 4.0045e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2844\n",
      "Epoch 44/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1136 - cls_loss: 0.0817 - box_loss: 6.3687e-04 - reg_l2_loss: 0.0620 - loss: 0.1756 - learning_rate: 3.0847e-04 - gradient_norm: 1.0204 - val_det_loss: 2.2128 - val_cls_loss: 2.1931 - val_box_loss: 3.9544e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2748\n",
      "Epoch 45/50\n",
      "312/312 [==============================] - 84s 269ms/step - det_loss: 0.1105 - cls_loss: 0.0800 - box_loss: 6.0861e-04 - reg_l2_loss: 0.0620 - loss: 0.1725 - learning_rate: 2.0749e-04 - gradient_norm: 0.9906 - val_det_loss: 2.2079 - val_cls_loss: 2.1880 - val_box_loss: 3.9945e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2699\n",
      "Epoch 46/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1101 - cls_loss: 0.0794 - box_loss: 6.1301e-04 - reg_l2_loss: 0.0620 - loss: 0.1721 - learning_rate: 1.2620e-04 - gradient_norm: 0.9971 - val_det_loss: 2.2066 - val_cls_loss: 2.1869 - val_box_loss: 3.9354e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2686\n",
      "Epoch 47/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1103 - cls_loss: 0.0797 - box_loss: 6.1042e-04 - reg_l2_loss: 0.0620 - loss: 0.1722 - learning_rate: 6.4942e-05 - gradient_norm: 0.9696 - val_det_loss: 2.2103 - val_cls_loss: 2.1906 - val_box_loss: 3.9448e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2723\n",
      "Epoch 48/50\n",
      "312/312 [==============================] - 79s 252ms/step - det_loss: 0.1121 - cls_loss: 0.0809 - box_loss: 6.2244e-04 - reg_l2_loss: 0.0620 - loss: 0.1741 - learning_rate: 2.3962e-05 - gradient_norm: 1.0048 - val_det_loss: 2.2110 - val_cls_loss: 2.1912 - val_box_loss: 3.9523e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2730\n",
      "Epoch 49/50\n",
      "312/312 [==============================] - 79s 253ms/step - det_loss: 0.1098 - cls_loss: 0.0793 - box_loss: 6.0903e-04 - reg_l2_loss: 0.0620 - loss: 0.1718 - learning_rate: 3.4303e-06 - gradient_norm: 1.0029 - val_det_loss: 2.2106 - val_cls_loss: 2.1907 - val_box_loss: 3.9780e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2726\n",
      "Epoch 50/50\n",
      "312/312 [==============================] - 83s 267ms/step - det_loss: 0.1126 - cls_loss: 0.0816 - box_loss: 6.1901e-04 - reg_l2_loss: 0.0620 - loss: 0.1746 - learning_rate: 3.4301e-06 - gradient_norm: 1.0254 - val_det_loss: 2.2098 - val_cls_loss: 2.1900 - val_box_loss: 3.9654e-04 - val_reg_l2_loss: 0.0620 - val_loss: 2.2718\n"
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data, model_spec=spec, batch_size=8, train_whole_model=True, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:05:54.983453: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir='.', export_format=[ExportFormat.SAVED_MODEL, ExportFormat.LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:07:46.902312: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 1.767 G  ops, equivalently 0.883 G  MACs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:07:52.361831: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-04-20 11:07:52.361859: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "model.export(export_dir='.', tflite_filename='model.tflite', quantization_config=QuantizationConfig.for_float16(), export_format=[ExportFormat.TFLITE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:08:31.895798: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-04-20 11:08:31.895838: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-04-20 11:08:31.920150: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 616.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-04-20 11:08:31.920181: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2023-04-20 11:08:31.990099: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-04-20 11:08:31.990142: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-04-20 11:08:42.039051: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 600.00MiB (rounded to 629145600)requested by op keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/efficientnet-lite0/StatefulPartitionedCall/blocks_1/tpu_batch_normalization/FusedBatchNormV3\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-20 11:08:42.046778: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *****_************_*_*******x********************_______***********************_____________________\n",
      "2023-04-20 11:08:42.046989: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at fused_batch_norm_op.cc:1380 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[64,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[64,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node blocks_1/tpu_batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[GatherNd_112/_1050]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[64,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node blocks_1/tpu_batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference__get_detections_647760]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(test_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py:143\u001b[0m, in \u001b[0;36mObjectDetector.evaluate\u001b[0;34m(self, data, batch_size)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    138\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe size of the validation_data (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) couldn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39msmaller than batch_size (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m). To solve this problem, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mset the batch_size smaller or increase the size of the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    141\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mvalidation_data.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(data), batch_size))\n\u001b[0;32m--> 143\u001b[0m eval_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_spec\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, ds, steps,\n\u001b[1;32m    144\u001b[0m                                         data\u001b[39m.\u001b[39;49mannotations_json_file)\n\u001b[1;32m    145\u001b[0m \u001b[39m# Set back drop_remainder=True since it must be True during training.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m# Otherwise it will fail.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_spec\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdrop_remainder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py:341\u001b[0m, in \u001b[0;36mEfficientDetModelSpec.evaluate\u001b[0;34m(self, model, dataset, steps, json_file)\u001b[0m\n\u001b[1;32m    339\u001b[0m progbar \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mProgbar(steps)\n\u001b[1;32m    340\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset):\n\u001b[0;32m--> 341\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mds_strategy\u001b[39m.\u001b[39;49mrun(_get_detections, (images, labels))\n\u001b[1;32m    342\u001b[0m   progbar\u001b[39m.\u001b[39mupdate(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/one_device_strategy.py:186\u001b[0m, in \u001b[0;36mOneDeviceStrategy.run\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, fn, args\u001b[39m=\u001b[39m(), kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Run `fn` on each replica, with the given arguments.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[39m  In `OneDeviceStrategy`, `fn` is simply called within a device scope for the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m    Return value from running `fn`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(OneDeviceStrategy, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrun(fn, args, kwargs, options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/one_device_strategy.py:394\u001b[0m, in \u001b[0;36mOneDeviceExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m strategy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\n\u001b[1;32m    393\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device), _OneDeviceReplicaContext(strategy):\n\u001b[0;32m--> 394\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[64,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node blocks_1/tpu_batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[GatherNd_112/_1050]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[64,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node blocks_1/tpu_batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference__get_detections_647760]"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#test model.tflite with test_set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m from_file \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcreate(\u001b[39m'\u001b[39m\u001b[39mmodel.tflite\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabels.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m from_file\u001b[39m.\u001b[39mevaluate(test_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#test model.tflite with test_set\n",
    "from_file = model.create('model.tflite', 'labels.txt')\n",
    "from_file.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label_map \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexported_label_map\n\u001b[1;32m      2\u001b[0m from_tflite \u001b[39m=\u001b[39m object_detector\u001b[39m.\u001b[39mObjectDetector(model_spec\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel.tflite\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
